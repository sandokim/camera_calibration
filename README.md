## ì»¤ìŠ¤í…€ ì¹´ë©”ë¼ ë³´ì • ë° ìì„¸ ì¶”ì • í”„ë¡œì„¸ìŠ¤ 

### 1. ì¹´ë©”ë¼ ë‚´ë¶€ íŒŒë¼ë¯¸í„° ì¶”ì • (`camera_calibration_intrinsics.py`)
- **ì‹¤í–‰ ë¹ˆë„:** ì¹´ë©”ë¼ë‹¹ í•œ ë²ˆë§Œ ì‹¤í–‰
- **ì…ë ¥:** ì¹´ë©”ë¼ë‹¹ 20ì¥ ì´ìƒì˜ ì²´ì»¤ë³´ë“œ ì´ë¯¸ì§€
- **ëª©ì :** ì¹´ë©”ë¼ì˜ ë‚´ë¶€ íŒŒë¼ë¯¸í„°(ì´ˆì  ê±°ë¦¬, ê´‘í•™ ì¤‘ì‹¬, ì™œê³¡ ê³„ìˆ˜)ë¥¼ êµ¬í•¨
- **ì¶œë ¥:** ê° ì¹´ë©”ë¼ë³„ë¡œ intrinsics.json íŒŒì¼ ìƒì„±

### 2. ì¹´ë©”ë¼ ì™¸ë¶€íŒŒë¼ë¯¸í„° ì¶”ì • (`camera_calibration_extrinsics.py`)
- **ì‹¤í–‰ ë¹ˆë„:** ë°ì´í„°ì…‹ êµ¬ì¶• ì‹œë§ˆë‹¤ ì‹¤í–‰
- **ì…ë ¥:** ë©€í‹° ì¹´ë©”ë¼ ì„¸íŒ…ì—ì„œ ë™ì‹œ ì´¬ì˜ëœ ì²´ì»¤ë³´ë“œ ì´ë¯¸ì§€ ìµœì†Œ 20ì¥ ì´ìƒ
- **ëª©ì :** ê³µí†µëœ í•˜ë‚˜ì˜ ì¢Œí‘œê³„ì—ì„œ ì¹´ë©”ë¼ ì™¸ë¶€ íŒŒë¼ë¯¸í„°(ì¹´ë©”ë¼ í¬ì¦ˆ) ì¶”ì •
- **ì¶œë ¥:**
  - PnP ì•Œê³ ë¦¬ì¦˜ì„ í†µí•´ ì²´ì»¤ë³´ë“œ ì¢Œí‘œê³„(world frame)ì—ì„œ ì¹´ë©”ë¼ ì¢Œí‘œê³„(camera frame)ë¡œì˜ ë³€í™˜ í–‰ë ¬ ê³„ì‚°
  - cam0ë¥¼ referenceë¡œ ì‚¼ê³  ë‚˜ë¨¸ì§€ ì¹´ë©”ë¼ë“¤ì˜ ì™¸ë¶€ íŒŒë¼ë¯¸í„° ê³„ì‚°
  - extrinsics.jsonìœ¼ë¡œ ì¹´ë©”ë¼ í¬ì¦ˆ ì €ì¥ 

checkerboardë¡œ êµ¬í•œ extrinsicsì™€ intrinsicsë¥¼ ë‹¤ìŒê³¼ ê°™ì´ ë³µì‚¬í•˜ê³ ,
scene/face/images/camXì— ë“¤ì–´ìˆëŠ” imageì˜ ì´ë¦„ì„ extrinsics.jsonì— ë§ê²Œ ìˆ˜ì •

```python
+â”€â”€ scene/myface/images


+â”€â”€ scene/myface
â”‚   +â”€â”€ extrinsics.json
â”‚   +â”€â”€ images
â”‚   â”‚   +â”€â”€ cam0
â”‚   â”‚   â”‚   +â”€â”€ cam0_img0.jpg
â”‚   â”‚   â”‚   +â”€â”€ intrinsics.json
â”‚   â”‚   +â”€â”€ cam1
â”‚   â”‚   â”‚   +â”€â”€ cam1_img0.jpg
â”‚   â”‚   â”‚   +â”€â”€ intrinsics.json
â”‚   â”‚   +â”€â”€ cam2
â”‚   â”‚   â”‚   +â”€â”€ cam2_img0.jpg
â”‚   â”‚   â”‚   +â”€â”€ intrinsics.json
â”‚   â”‚   +â”€â”€ cam3
â”‚   â”‚   â”‚   +â”€â”€ cam3_img0.jpg
â”‚   â”‚   â”‚   +â”€â”€ intrinsics.json

+â”€â”€ scene/4_camera_calib_data
â”‚   +â”€â”€ checkerboard
â”‚   â”‚   +â”€â”€ cam0
â”‚   â”‚   â”‚   +â”€â”€ cam0_checkerboard_img0.jpg
â”‚   â”‚   â”‚   +â”€â”€ cam0_checkerboard_img1.jpg
â”‚   â”‚   â”‚   +â”€â”€ cam0_checkerboard_img2.jpg
â”‚   â”‚   â”‚   ...
â”‚   â”‚   â”‚   +â”€â”€ intrinsics.json
â”‚   â”‚   +â”€â”€ cam1
â”‚   â”‚   â”‚   +â”€â”€ cam1_checkerboard_img0.jpg
â”‚   â”‚   â”‚   +â”€â”€ cam1_checkerboard_img1.jpg
â”‚   â”‚   â”‚   +â”€â”€ cam1_checkerboard_img2.jpg
â”‚   â”‚   â”‚   ...
â”‚   â”‚   â”‚   +â”€â”€ intrinsics.json
â”‚   â”‚   +â”€â”€ cam2
â”‚   â”‚   â”‚   +â”€â”€ cam2_checkerboard_img0.jpg
â”‚   â”‚   â”‚   +â”€â”€ cam2_checkerboard_img1.jpg
â”‚   â”‚   â”‚   +â”€â”€ cam2_checkerboard_img2.jpg
â”‚   â”‚   â”‚   ...
â”‚   â”‚   â”‚   +â”€â”€ intrinsics.json
â”‚   â”‚   +â”€â”€ cam3
â”‚   â”‚   â”‚   +â”€â”€ cam3_checkerboard_img0.jpg
â”‚   â”‚   â”‚   +â”€â”€ cam3_checkerboard_img1.jpg
â”‚   â”‚   â”‚   +â”€â”€ cam3_checkerboard_img2.jpg
â”‚   â”‚   â”‚   ...
â”‚   â”‚   â”‚   +â”€â”€ intrinsics.json
â”‚   â”‚   +â”€â”€ multicapture
â”‚   â”‚   â”‚   +â”€â”€ cam0
â”‚   â”‚   â”‚   â”‚   +â”€â”€ cam0_checkerborard_img_x.jpg
â”‚   â”‚   â”‚   +â”€â”€ cam1
â”‚   â”‚   â”‚   â”‚   +â”€â”€ cam1_checkerborard_img_x.jpg
â”‚   â”‚   â”‚   +â”€â”€ cam2
â”‚   â”‚   â”‚   â”‚   +â”€â”€ cam2_checkerborard_img_x.jpg
â”‚   â”‚   â”‚   +â”€â”€ cam3
â”‚   â”‚   â”‚   â”‚   +â”€â”€ cam3_checkerborard_img_x.jpg
â”‚   â”‚   +â”€â”€ extrinsics.json
â”‚   â”‚   +â”€â”€ other_scene_images
```


### 3. COLMAP í˜•íƒœì˜ cameras.txt, images.txtë¡œ ì €ì¥
- **ì…ë ¥:** intrinsics.json, extrinsics.json
- **ëª©ì :** COLMAP í˜•íƒœì˜ ì¹´ë©”ë¼ íŒŒë¼ë¯¸í„° ì €ì¥
- **ì¶œë ¥:** cameras.txt, images.txt, points3D.txt(empty)


### 4. [sparse/0/ í´ë” ìƒì„± í›„ 3.ì—ì„œ ì¶œë ¥í•œ cameras.txt, images.txt, points3D.txt(empty)ë¥¼ ë³µì‚¬](https://colmap.github.io/faq.html#reconstruct-sparse-dense-model-from-known-camera-poses)
If the camera poses are known and you want to reconstruct a sparse or dense model of the scene, you must first manually construct a sparse model by creating a `cameras.txt, points3D.txt`, and `images.txt` under a new folder:

`python convert_to_COLMAP_fmt.py`ë¥¼ ì‹¤í–‰í•˜ë©´ ë‹¤ìŒê³¼ ê°™ì€ í´ë”ê°€ ìƒì„±ë˜ê³ , triangulationì´ ìˆ˜í–‰ë˜ì–´, `triangulated/sparse/0` í´ë”ê°€ ìƒì„±ë¨
COLMAPì˜ `model_convert`ë¥¼ í†µí•´ `triangulated/sparse/0` í´ë”ì— ìƒì„±ëœ `bin` íŒŒì¼ì„ `txt` íŒŒì¼ í˜•ì‹ìœ¼ë¡œë„ ë³€í™˜í•˜ì—¬ ì €ì¥

```python
+â”€â”€ manually/created/sparse/model
â”‚   +â”€â”€ cameras.txt
â”‚   +â”€â”€ images.txt
â”‚   +â”€â”€ points3D.txt
+â”€â”€ triangulated/sparse/0
â”‚   +â”€â”€ cameras.txt
â”‚   +â”€â”€ images.txt
â”‚   +â”€â”€ points3D.txt
â”‚   +â”€â”€ cameras.bin
â”‚   +â”€â”€ images.bin
â”‚   +â”€â”€ points3D.bin
```

The points3D.txt file should be empty while every other line in the images.txt should also be empty, since the sparse features are computed, as described below. You can refer to this article for more information about the structure of a sparse model.

#### COLMAPì—ì„œ Import Modelë¡œ sparse/0/ í´ë” ì„ íƒí•˜ì˜€ìœ¼ë‚˜ COLMAP Processing > Database managementì—ì„œ Camerasì™€ Imagesê°€ ëª¨ë‘ ë¹„ì–´ìˆìŒ

COLMAPì€ .txt íŒŒì¼ ê¸°ë°˜ì˜ ëª¨ë¸ì„ GUIì—ì„œ ì§ì ‘ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ëŒ€ì‹  database.dbë¥¼ ì§ì ‘ êµ¬ì„±í•˜ê±°ë‚˜ ë³€í™˜í•˜ì—¬ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ìœ ì¼í•œ ë°©ë²•ì…ë‹ˆë‹¤. GUI/CLI ëª¨ë‘ ë™ì¼í•˜ê²Œ database.db â†’ ëª¨ë“  ì´ë¯¸ì§€, ì¹´ë©”ë¼, feature ì •ë³´ ì‚¬ìš©

The image reader can only take the parameters for a single camera. If you want to specify the parameters for multiple cameras, you would have to modify the SQLite database directly. This should be easy by modifying the `scripts/python/database.py` script.

#### Question: How to format cameras.txt for Reconstruct sparse/dense model from known camera poses #428 
[different cameras with different intrinsics, multiple camerasì˜ parametersë¥¼ ì§€ì •í•˜ë ¤ë©´ SQLite databaseë¥¼ ì§ì ‘ ìˆ˜ì •í•´ì•¼í•˜ê³ , ì´ëŠ” `colmap/scripts/python/database.py` ìŠ¤í¬ë¦½íŠ¸ë¡œ ê°€ëŠ¥í•˜ë‹¤.](https://github.com/colmap/colmap/issues/428)

#### gaussian_splattingì„ ìœ„í•´ì„  convert_to_COLMAP_fmt.pyì—ì„œ OpenCV ì¹´ë©”ë¼ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì˜€ê¸°ì—, intrinsicsë¥¼ ì‚¬ìš©í•˜ì—¬, undistortioní•œ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•˜ì—¬ì•¼ í•¨
- undistortionì´ ì•„ì§ ì•ˆëœ ì´ë¯¸ì§€ë“¤ì„ -> `multicam/build/Desktop_Qt_6_9_0_MSVC2022_64bit-Release/scene/myface_undistort/input` ì— ë„£ê¸°
- `multicam/build/Desktop_Qt_6_9_0_MSVC2022_64bit-Release/scene/myface_undistort/distorted` í´ë” ì•ˆì— `database.db`ì™€ `triangulated/sparse/0` í´ë”ë¥¼ ë³µì‚¬
- `triangulated/sparse/0`ì—ì„œ ì–»ì—ˆë˜ `cameras.txt, images.txt, points3D.txt` -> `distorted/sparse/0`ì— ë³µì‚¬í–ˆìŒ

```python
<location>
|---input
|   |---<image 0>
|   |---<image 1>
|   |---...
|---distorted
    |---database.db
    |---sparse
        |---0
            |---...
```

- `convert.py`ë¥¼ ì‹¤í–‰í•˜ë©´ undistortedëœ ì´ë¯¸ì§€ë“¤ì€ `images` í´ë”ì— ìƒì„±ë¨

```python
<location>
â”œâ”€â”€ input/                   # (1) ì›ë³¸ ì´ë¯¸ì§€ (ì™œê³¡ í¬í•¨)
â”‚   â”œâ”€â”€ image0.jpg
â”‚   â”œâ”€â”€ image1.jpg
â”‚   â””â”€â”€ ...
â”œâ”€â”€ distorted/              # (2) COLMAP ì‘ì—… ê³µê°„ (ì™œê³¡ í¬í•¨)
â”‚   â”œâ”€â”€ database.db         # COLMAPìš© DB (ì™œê³¡ í¬í•¨ ì´ë¯¸ì§€ ê¸°ì¤€)
â”‚   â””â”€â”€ sparse/
â”‚       â””â”€â”€ 0/
â”‚           â””â”€â”€ cameras.bin
â”‚           â””â”€â”€ images.bin
â”‚           â””â”€â”€ points3D.bin
â”œâ”€â”€ images/                 # (3) Undistorted ì´ë¯¸ì§€ (Pinhole ê¸°ì¤€ ë³€í™˜ë¨)
â”œâ”€â”€ sparse/                 # (4) Undistorted ê¸°ì¤€ ì¬êµ¬ì„± ê²°ê³¼
â”‚   â””â”€â”€ 0/
â”‚       â””â”€â”€ cameras.bin
â”‚       â””â”€â”€ images.bin
â”‚       â””â”€â”€ points3D.bin
```

- ë¯¸ë¦¬ COLMAPì˜ feature extraction, feature matchingì„ ì‹¤í–‰í•˜ì—¬, `database.db`ì— ì €ì¥í–ˆì—ˆê¸° ë•Œë¬¸ì—, `convert.py`ì—ì„œëŠ” feature extraction, feature matchingì„ ì‹¤í–‰í•˜ì§€ ì•ŠìŒ -> `convert.py`ì—ì„œ skip matchingì„ í•˜ë©´ feature extraction, feature matching, mapper((SfM & triangulation) + bundle adjustment)ì„ ì‹¤í–‰í•˜ì§€ ì•ŠìŒ
- ë³¸ì¸ì€ `convert_to_COLMAP_fmt.py`ì—ì„œ feature extraction, feature matchingì„ ìˆ˜í–‰í•˜ê³ , ë¯¸ë¦¬ PnP ì•Œê³ ë¦¬ì¦˜ì„ í†µí•´ ê³„ì‚°í•œ ì¹´ë©”ë¼ í¬ì¦ˆë¥¼ ì£¼ì—ˆê³ , ì´ ì¹´ë©”ë¼ í¬ì¦ˆë¥¼ ì‚¬ìš©í•˜ì—¬ point triangulatorë¥¼ ìˆ˜í–‰í•˜ì˜€ì§€ë§Œ, bundle adjustmentëŠ” ì‹¤í–‰í•˜ì§€ ì•Šì•˜ìŒ -> bundle adjustmentë„ ì¶”ê°€í•˜ì
  <p align="center">
    <img src="https://github.com/user-attachments/assets/90ac44df-36aa-4389-8d69-41d78d6ba8b5" width="600"/>
  </p>
  <p align="center"><em>Structure-from-Motion (SfM) Pipeline : [Source](http://theia-sfm.org/sfm.html)</em></p>
- Traditional SfM pipelines such as COLMAP, operate by taking a sequence of images, detecting features points and descriptors images and matching these features across different views. RANSAC is then used to filter out bad matches while maximizing inliers. Using triangulation, camera poses are estimated and iteratively refined using Bundle Adjustment (BA) with an objective to minimize reprojection errors.

###  Limitations of Traditional SfM:
Traditional SfM methods require the camera intrinsics to be known beforehand limiting their applicability in scenarios where camera parameters are unknown or missing. **These methods typically consider only a handful of keypoints to obtain sparse point clouds discarding the global geometric context of the scene.** They are often time consuming and complex, involving multiple intermediate stages potentially introducing noise. They donâ€™t handle scenes with low texture or repetitive patters well. **Bundle adjustment, a key step in refining 3D points is computationally intensive especially for larger scenes.** They require highly overlapping image sequences and camera motion for accurate reconstruction.

- BAëŠ” ê¸°ì¡´ì˜ 3D êµ¬ì¡°ì™€ ì¹´ë©”ë¼ í¬ì¦ˆë¥¼ ì •ë°€í•˜ê²Œ ì •í•©í•˜ëŠ” ìµœì í™” ê³¼ì •ì…ë‹ˆë‹¤. **bundle adjustmentì—ì„œëŠ” 2D reprojection errorë¥¼ ìµœì†Œí™”í•©ë‹ˆë‹¤.** Bundle Adjustment(BA)ë¥¼ ìˆ˜í–‰í•˜ì§€ ì•Šìœ¼ë©´ í¬ì¦ˆ ë° 3D êµ¬ì¡° ê°„ì˜ ì •í•© ìµœì í™”ê°€ ì´ë£¨ì–´ì§€ì§€ ì•ŠìŒ. ë‹¨, bundle adjustmentëŠ” feature matchingì—ì„œ ì°¾ì•„ì§„ ëŒ€ì‘ì  ê´€ê³„ê°€ ë¶€ì •í™•í•˜ë©´, triangulationìœ¼ë¡œ ì°¾ì•„ì§„ 3D ì ë“¤ì˜ ìœ„ì¹˜ë„ ë¶€ì •í™•í•´ì§ˆ ìˆ˜ ìˆê³ , bundle adjustment ê²°ê³¼ë„ ë¶€ì •í™•í•´ì§ˆ ìˆ˜ ìˆìŒ. ì¦‰, ì´ˆê¸° ì…ë ¥ê°’(3D ì , ëŒ€ì‘ì , í¬ì¦ˆ)ì´ ë¶€ì •í™•í•˜ê±°ë‚˜ ë¶€ì¡±í•˜ë‹¤ë©´, BAëŠ” ì˜¤ì°¨ë¥¼ ì¤„ì´ëŠ” ëŒ€ì‹ , ì˜ëª»ëœ ë°©í–¥ìœ¼ë¡œ ìˆ˜ë ´í•˜ê±°ë‚˜ ê³¼ì í•©(overfitting)ì˜ í˜•íƒœë¡œ ìˆ˜ë ´í•  ìˆ˜ ìˆìŒ
- 3D ì ì˜ ë°€ë„ê°€ ì¶©ë¶„í•˜ì§€ ì•Šì„ ê²½ìš°, reconstructëœ 3D ì ë“¤ì´ sparseí•˜ê³ , ì¥ë©´ êµ¬ì¡°ë¥¼ ì¶©ë¶„íˆ í¬ê´„í•˜ì§€ ëª»í•˜ë©´ ì¹´ë©”ë¼ í¬ì¦ˆ ê°„ ì œì•½ ì¡°ê±´ì´ ì•½í•´ì§. ëŒ€ì‘ì  ê¸°ë°˜ ì—ëŸ¬ ìµœì†Œí™”ê°€ ì „ì²´ ì¥ë©´ ì •í•©ì„±ìœ¼ë¡œ ì—°ê²°ë˜ì§€ ì•ŠìŒ. ì´ëŸ° ê²½ìš° BAë¥¼ ìˆ˜í–‰í•´ë„ ìµœì í™”ì— ì¶©ë¶„í•œ ì •ë³´ê°€ ë¶€ì¡±í•˜ì—¬, ê²°ê³¼ê°€ ë¬´ì˜ë¯¸í•˜ê±°ë‚˜ ì˜¤íˆë ¤ ë‚˜ë¹ ì§ˆ ìˆ˜ ìˆìŒ

### convert.pyì—ì„œëŠ” feature extraction, feature matching, mapper ê°€ ìˆ˜í–‰ë˜ì—ˆê³ , mapperëŠ” ì¹´ë©”ë¼ í¬ì¦ˆ ê³„ì‚° (SfM)ê³¼ triangulationì„ ìˆ˜í–‰í•œ í›„ì— (local+global) bundle adjustmentë¥¼ ìˆ˜í–‰í•¨

```
python convert.py -s multicam/build/Desktop_Qt_6_9_0_MSVC2022_64bit-Release/scene/myface_undistort --skip_matching
```

ê° ì¹´ë©”ë¼ë§ˆë‹¤ intrinsicsê°€ ë‹¬ëì–´ì„œ, undistortionëœ ì´ë¯¸ì§€ë“¤ì˜ ì‚¬ì´ì¦ˆê°€ ë‹¤ë¥´ê²Œ ìƒì„±ë¨

## ì¹´ë©”ë¼ ë‚´ë¶€íŒŒë¼ë¯¸í„° ì„¤ì •
- image_undistorterëŠ” ì´ë¯¸ì§€ë¥¼ ideal pinhole camera ëª¨ë¸ë¡œ ë³€í™˜í•˜ëŠ” ê³¼ì •ì—ì„œ, projection ì¤‘ì‹¬(cx, cy) ê¸°ì¤€ìœ¼ë¡œ ìœ íš¨í•œ ì‹œì•¼ ì˜ì—­ë§Œì„ ìœ ì§€í•¨.
- ë”°ë¼ì„œ ì¶”ì •ëœ intrinsicsì˜ cx, cyê°€ ì´ë¯¸ì§€ ì¤‘ì‹¬ì—ì„œ í¬ê²Œ ë²—ì–´ë‚œ ê²½ìš°, warped ì˜ì—­ì´ ì´ë¯¸ì§€ ë°–ìœ¼ë¡œ ë°€ë ¤ cropì´ ì‹¬í•˜ê²Œ ë°œìƒí•¨
- **camera_calibration_intrinsics.pyì—ì„œ ì²´ì»¤ë³´ë“œ íŒ¨í„´ìœ¼ë¡œ ì¶”ì •í•œ intrinsicsì¸ mtxì—ì„œ ì„ì˜ë¡œ mtx[0,2] = W/2, mtx[1,2] = H/2ë¡œ ëŒ€ì²´í•˜ì—¬ì„œ cropì´ ì‹¬í•˜ê²Œ ë˜ëŠ” ë¶€ë¶„ì´ í•´ê²°ë˜ì—ˆìŒ**
ì¹´ë©”ë¼ì˜ **ë‚´ë¶€ íŒŒë¼ë¯¸í„°(intrinsic parameters)**ëŠ” ì¼ë°˜ì ìœ¼ë¡œ ë‹¤ìŒê³¼ ê°™ì€ ì„¸ ê°€ì§€ ìš”ì†Œë¡œ êµ¬ì„±ë©ë‹ˆë‹¤: 2D Translation Matrix, 2D Scaling Matrix, ê·¸ë¦¬ê³  2D Shear Matrixì…ë‹ˆë‹¤.
- 2D Translation MatrixëŠ” **principal point(ì£¼ì )**ì˜ ìœ„ì¹˜ë¥¼ ë‚˜íƒ€ë‚´ë©°, ì´ëŠ” ì´ë¯¸ì§€ ì¢Œí‘œê³„ì—ì„œ ê´‘ì¶•ì´ í†µê³¼í•˜ëŠ” ì ì…ë‹ˆë‹¤. **ëŒ€ë¶€ë¶„ì˜ ê²½ìš°, ì´ ì£¼ì ì€ ì´ë¯¸ì§€ì˜ ì¤‘ì‹¬ì— ìœ„ì¹˜í•œë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤.**
- 2D Shear MatrixëŠ” ì´ë¯¸ì§€ ì¶• ê°„ì˜ ë¹„ì§êµì„±ì„ í‘œí˜„í•©ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì‹¤ì œ ëŒ€ë¶€ë¶„ì˜ ì¹´ë©”ë¼ì—ì„œëŠ” í”½ì…€ì˜ x, yì¶•ì´ ì§êµí•œë‹¤ê³  ê°€ì •í•˜ê¸° ë•Œë¬¸ì—, ì´ í•­ì€ ë¬´ì‹œë˜ëŠ” ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤.
- 2D Scaling MatrixëŠ” ì´ë¯¸ì§€ì˜ xì¶•ê³¼ yì¶• ë°©í–¥ì— ëŒ€í•œ **focal length(ì´ˆì  ê±°ë¦¬)**ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ì´ˆì  ê±°ë¦¬ëŠ” ì´ë¯¸ì§€ ì„¼ì„œì™€ ì´ë¯¸ì§€ í‰ë©´ ì‚¬ì´ì˜ ê±°ë¦¬ë¡œ í•´ì„í•  ìˆ˜ ìˆìœ¼ë©°, ì´ ê°’ì€ ì¹´ë©”ë¼ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ì—ì„œ í•µì‹¬ì ìœ¼ë¡œ ì¶”ì •í•˜ëŠ” íŒŒë¼ë¯¸í„°ì…ë‹ˆë‹¤.
- ë”°ë¼ì„œ ì‹¤ì œ ì‘ìš©ì´ë‚˜ ë³¸ ë…¼ë¬¸ì—ì„œëŠ” intrinsic parameters ì¤‘ focal lengthì— í•´ë‹¹í•˜ëŠ” scaling ìš”ì†Œë§Œì„ ì¶”ì • ëŒ€ìƒìœ¼ë¡œ ì‚¼ê³  ìˆìœ¼ë©°, **ë‚˜ë¨¸ì§€ ìš”ì†Œë“¤ì€ ê³ ì •(principal point)**ë˜ê±°ë‚˜ **ë¬´ì‹œ(shear)**ë˜ëŠ” ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤.

## image_undistorter ëª…ë ¹
- ì™œê³¡ ì œê±°ëœ ì´ë¯¸ì§€ì™€ í•¨ê»˜, ì´ ì´ë¯¸ì§€ì— ë§ëŠ” ideal PINHOLE (ë˜ëŠ” SIMPLE_PINHOLE) ì¹´ë©”ë¼ ëª¨ë¸ì„ ìƒì„±í•¨
- 'image undistorter' ëª…ë ¹ì„ ìˆ˜í–‰í•œë‹¤ê³  í•´ì„œ database.db ë‚´ OpenCV ëª¨ë¸ì´ PINHOLEë¡œ ìë™ ë³€í™˜ë˜ì§€ëŠ” ì•ŠìŠµë‹ˆë‹¤.
- ëŒ€ì‹ , undistorted ê²°ê³¼ì— ëŒ€ì‘í•˜ëŠ” PINHOLE ëª¨ë¸ì´ ë³„ë„ íŒŒì¼(cameras.txt ë“±)ì— ìƒì„±ë  ë¿ì…ë‹ˆë‹¤.

### poses_bounds.npy ìƒì„±
```python
git clone https://github.com/Fyusion/LLFF
python LLFF/imgs2poses.py multicam/build/Desktop_Qt_6_9_0_MSVC2022_64bit-Release/scene/myface_undistort
```

### GS í•™ìŠµ ì„±ê³µ!
```python
<KIST_llff>
|---images
|   |---<image 0>
|   |---<image 1>
|   |---...
|---sparse
|    |---0
|        |---cameras.bin
|        |---images.bin
|        |---points3D.bin
|---poses_bounds.npy   
```

------------------------------------------------------------------------------------------------------------------
# To do list
- feature extractionì„ denseí•˜ê²Œ ìˆ˜í–‰í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•˜ê³ , feature matchingì„ ìˆ˜í–‰í•˜ê³ , PnP ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ êµ¬í•œ ì¹´ë©”ë¼ í¬ì¦ˆì™€ í•¨ê»˜, ì•ì„œ êµ¬í•œ feature matchingìœ¼ë¡œ ì°¾ì•„ì§„ correspondencesê°€ 2ê°œ ì´ìƒì¼ ê²½ìš°ì—ë„ triangulationí•˜ì—¬ 3D í¬ì¸íŠ¸ë¥¼ reconstructí•˜ëŠ” ì•Œê³ ë¦¬ì¦˜ì„ êµ¬í˜„í•´ì•¼í•˜ê³ , ì¶”ê°€ì ìœ¼ë¡œ ì¹´ë©”ë¼ í¬ì¦ˆ ë° 3D êµ¬ì¡°ê°„ì˜ ì •í•© ìµœì í™”ë¥¼ ìœ„í•œ Bundle Adjustment(BA)ë¥¼ ìˆ˜í–‰í•´ì•¼ë§Œ í•¨

## Triangulation with more than 3 correspondences (cv2.sfm)

- [OPENCV_EXTRA_MODULESì— sfmì´ í¬í•¨ë˜ì–´ ìˆìŒ](https://github.com/opencv/opencv_contrib/blob/master/modules/sfm/src/triangulation.cpp)
- `cv2.sfm` ëª¨ë“ˆì€ OpenCVì˜ contrib ëª¨ë“ˆ ì¤‘ í•˜ë‚˜ì´ë©°, ê¸°ë³¸ OpenCV ì„¤ì¹˜ì—ëŠ” í¬í•¨ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. cv2.sfmì„ ì‚¬ìš©í•˜ë ¤ë©´ OpenCVë¥¼ ì†ŒìŠ¤ì—ì„œ ì§ì ‘ ë¹Œë“œí•´ì•¼í•¨

### cv2.sfmì„ ì‚¬ìš©í•˜ê¸° ìœ„í•œ python 3.11 ê°€ìƒí™˜ê²½ ìƒˆë¡œ êµ¬ì¶• (mast3rì˜ faiss-gpu ì‚¬ìš©ì„ ìœ„í•´ CUDA 12.1ë¡œ ì„¤ì¹˜)
```python
# mast3r ì„¤ì¹˜
conda create -n mast3r python=3.11 cmake=3.14.0 -y
conda activate mast3r 
pip install "numpy<2.0"
## cv2.sfm ì§ì ‘ ë¹Œë“œí•˜ì—¬ ì„¤ì¹˜
...
## mast34 ì„¤ì¹˜
conda install pytorch torchvision pytorch-cuda=12.1 -c pytorch -c nvidia  # cuda 12.1ë¡œ ì¬ì„¤ì¹˜
cd submodules/mast3r
pip install -r requirements.txt
pip install -r dust3r/requirements.txt
pip install -r dust3r/requirements_optional.txt
## opencv ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì œê±°
pip uninstall -y opencv-python opencv-python-headless

## compile and install ASMK
pip install cython

cd submodules/asmk/cython/
cythonize *.pyx
cd ..
conda install -c conda-forge faiss-gpu # faiss-gpu, containing both CPU and GPU indices, is available on Linux (x86-64 only) for CUDA 11.4 and 12.1 / For FRM, MASt3R pipeline internally uses Faiss library to store correspondences.
pip install .  # or python3 setup.py build_ext --inplace
cd ..


# DKM ì„¤ì¹˜
pip install submodules/DKM 
# DKM ì„¤ì¹˜ì‹œ ê°™ì´ ê¹”ë¦° opencv ë¼ì´ë¸ŒëŸ¬ë¦¬ ì œê±°
pip uninstall -y opencv-python opencv-python-headless
```

## Dense Matching Algorithm
- [DUSt3R](https://github.com/naver/dust3r)
  - DUSt3R ê¸°ë³¸ ëª¨ë¸ë¡œ pixelë³„ 3D pointë¥¼ ì˜ˆì¸¡í–ˆì—ˆìŠµë‹ˆë‹¤. ì´ ê´€ê³„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ focal lengthë„ ì˜ˆì¸¡í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- [MASt3R](https://github.com/naver/mast3r)
  - [MASt3R and MASt3R-SfM Explanation: Image Matching and 3D Reconstruction Results](https://learnopencv.com/mast3r-sfm-grounding-image-matching-3d/?utm_source=chatgpt.com)
  - In MASt3R, a pixel i in image 1 and a pixel j in image 2 are considered as true match if they correspond to the same ground truth 3D point. i.e. Each local descriptor in a image matches at max only a single descriptor in the other image. The network is trained to learn such descriptors while penalizing non-matching feature descriptors using InfoNCE loss which is much more effective than a simple 3D regression loss, as used in DUSt3R.
  - MASt3R effectively handles extreme viewpoint differences upto 180 degrees-scenarios that can be sometimes ambiguous to humans. This remarkable performance is primarily attributed to MASt3R and DUSt3Râ€™s 3D scene understanding and image matching techniques.
  <p align="center">
    <img src="https://github.com/user-attachments/assets/58dfdbfd-2c49-4a7c-bd21-ff1b696b7f59" width="600"/>
  </p>
  <p align="center"><em>MASt3R performance on Hard Cases</em></p>

- [DKM](https://github.com/Parskatt/DKM)

### ê¸°ì¡´ Image Matchingì˜ ë¬¸ì œì  
ì „í†µì ì¸ ì´ë¯¸ì§€ ë§¤ì¹­ ê¸°ë²•ì€ ì¼ë°˜ì ìœ¼ë¡œ ì„¸ ë‹¨ê³„ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤:
- (1) í‚¤í¬ì¸íŠ¸ ì¶”ì¶œ
- (2) ê° í‚¤í¬ì¸íŠ¸ì˜ ì£¼ë³€ ì˜ì—­ìœ¼ë¡œë¶€í„° ì§€ì—­ì ìœ¼ë¡œ ë¶ˆë³€í•˜ëŠ” descriptorë¥¼ ì¶”ì¶œ
- (3) Feaeture Spaceì—ì„œ descriptor ê°„ ê±°ë¦¬ ë¹„êµë¥¼ í†µí•´ í‚¤í¬ì¸íŠ¸ ë§¤ì¹­ ìˆ˜í–‰

ì´ëŸ¬í•œ ë°©ì‹ì€ ì¡°ëª… ë³€í™”ë‚˜ ì‹œì  ë³€í™”ì— ë¹„êµì  ê°•ì¸í•˜ë©°, ì ì€ ìˆ˜ì˜ í‚¤í¬ì¸íŠ¸ë§Œìœ¼ë¡œë„ ë°€ë¦¬ì´ˆ ë‹¨ìœ„ì˜ ë¹ ë¥¸ ë§¤ì¹­ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì „ì—­ì ì¸ ê¸°í•˜í•™ì  ë¬¸ë§¥(geometric context)ì„ ê³ ë ¤í•˜ì§€ ì•Šê¸° ë•Œë¬¸ì—, ë°˜ë³µ íŒ¨í„´ì´ë‚˜ ì €í…ìŠ¤ì²˜ ì˜ì—­ì—ì„œëŠ” ì˜¤ì°¨ê°€ ë°œìƒí•˜ê¸° ì‰½ìŠµë‹ˆë‹¤.

ì¼ë°˜ì ìœ¼ë¡œ Image Matchingì€ 2Dë¬¸ì œë¡œ ë‹¤ë¤„ì§€ê³  ìˆì—ˆìŠµë‹ˆë‹¤. ë°˜ë©´ DUSt3Rì—ì„œëŠ” Transformerê¸°ë°˜ìœ¼ë¡œ ë‘ ì´ë¯¸ì§€ì˜ pixelê³¼ 3D pointmapì˜ correspondence ì˜ˆì¸¡ì„ í†µí•´ 3Dê³µê°„ìƒì—ì„œ Image Matching ë¬¸ì œë¥¼ í’€ì—ˆìŠµë‹ˆë‹¤.
**í•˜ì§€ë§Œ DUSt3Rì´ 3D Reconstruction ëª©ì ìœ¼ë¡œ ë§Œë“¤ì–´ì¡Œê¸°ì—, ì‹œì  ë³€í™”ì—” ê°•ì¸í•˜ì§€ë§Œ Image Matchingì—ì„  ìƒëŒ€ì ìœ¼ë¡œ ë¶€ì •í™•í•©ë‹ˆë‹¤. MASt3Rì—ì„œëŠ” DUSt3Rì„ í™œìš©í•˜ì—¬ Image Matchingì— íŠ¹í™”í•˜ëŠ” ë°©ë²•ì— ê´€í•´ ë‹¤ë£¹ë‹ˆë‹¤.**

  <p align="center">
    <img src="https://github.com/user-attachments/assets/5ec51bfc-85d5-4bb6-b0ad-0ebffab5d600" width="600"/>
  </p>
  <p align="center"><em>MASt3R performance on extreme viewpoint differences</em></p>

ìœ„ ê·¸ë¦¼ì€ MASt3Rì—ì„œ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤. 2ê°œ ì…ë ¥ ì´ë¯¸ì§€ì˜ ê³µí†µ ì˜ì—­ì´ ì•„ì£¼ ì ìŒì—ë„ ë¶ˆêµ¬í•˜ê³ , 2Dë¬¸ì œê°€ ì•„ë‹ˆë¼ 3Dë¬¸ì œë¡œ í’€ì—ˆê¸° ë•Œë¬¸ì—, Image Matchingì´ ì˜ ëœë‹¤ëŠ” ê²ƒì„ ë³´ì—¬ì£¼ëŠ” ì´ë¯¸ì§€ì¸ ê²ƒ ê°™ìŠµë‹ˆë‹¤. 


## ğŸ” ìš©ì–´ ì •ë¦¬: "Dense Reconstruction"
Dense reconstructionì€ ì¼ë°˜ì ìœ¼ë¡œ MVS (Multi-View Stereo) ë¥¼ í†µí•´ ì¥ë©´ì˜ í‘œë©´ì„ ì¡°ë°€í•œ 3D í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ë˜ëŠ” meshë¡œ ë³µì›í•˜ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤.
ì´ë•ŒëŠ” triangulated sparse pointsê°€ ì•„ë‹Œ, í”½ì…€ ë‹¨ìœ„ë¡œ ëŒ€ì‘ì ì„ ì°¾ê³  ê¹Šì´ ì •ë³´ë¥¼ ì¶”ì •í•˜ì—¬ ìˆ˜ì‹­ë§Œ~ìˆ˜ë°±ë§Œ ê°œì˜ 3D ì ì„ ìƒì„±í•©ë‹ˆë‹¤.
â†’ COLMAPì—ì„œë„ MVSë¥¼ ì‚¬ìš©í•œ patch_match_stereo, stereo_fusion ì´í›„ê°€ ì§„ì§œ dense reconstructionì…ë‹ˆë‹¤.

### í”í•œ í˜¼ë™: Dense feature ì‚¬ìš© = dense reconstruction?
ì–´ë–¤ ì—°êµ¬ë‚˜ êµ¬í˜„ì—ì„œëŠ” dense feature matcher (e.g., LoFTR)ë§Œ ì‚¬ìš©í•´ë„ ì´ë¥¼ "dense reconstruction"ì´ë¼ ë¶€ë¥´ëŠ” ê²½ìš°ê°€ ìˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ì—„ë°€íˆ ë³´ë©´ ì´ê±´: dense correspondences ê¸°ë°˜ì˜ SfM ë˜ëŠ” dense SfM ì´ë¼ê³  ë¶€ë¥´ëŠ” ê²Œ ë” ì •í™•í•©ë‹ˆë‹¤.

## ğŸ” ìš©ì–´ ì •ë¦¬: Map-free relocalization
Map-free relocalizationì€ ê¸°ì¡´ì˜ ì§€ë„ ì—†ì´ ì£¼ì–´ì§„ ì´ë¯¸ì§€ì—ì„œ ì¹´ë©”ë¼ì˜ ìœ„ì¹˜ ë° ë°©í–¥(6DoF pose) ì„ ì¶”ì •í•˜ëŠ” ë¬¸ì œì…ë‹ˆë‹¤.
ì¦‰, SLAMì´ë‚˜ SfMìœ¼ë¡œ ë¯¸ë¦¬ êµ¬ì¶•ëœ 3D map ì—†ì´, ì˜¤ì§ ì´ë¯¸ì§€ ìŒ(ë˜ëŠ” ë‹¤ì¤‘ ì´ë¯¸ì§€)ë§Œìœ¼ë¡œ ìƒëŒ€ ìœ„ì¹˜ë¥¼ ì¶”ì •í•©ë‹ˆë‹¤.

#### ğŸ§  Map-free relocalizationì€ì€ ì™œ ì–´ë ¤ìš´ê°€?
- ì§€ë„ ì—†ì´ ì ˆëŒ€ ìœ„ì¹˜ë‚˜ ìŠ¤ì¼€ì¼ì„ ì•Œ ìˆ˜ ì—†ìŒ
- ì´ë¯¸ì§€ ê°„ ëŒ€ì‘ì ë§Œìœ¼ë¡œ metric scaleì˜ ì •í™•í•œ ìœ„ì¹˜ ì¶”ì •ì´ ì–´ë ¤ì›€
- ë‹¤ì–‘í•œ ì‹œì  ë³€í™”(viewpoint change) ì— ê°•ì¸í•´ì•¼ í•¨

#### MASt3R -> dense image matching & metric scale 3D pose estimation
- MASt3RëŠ” dense image matchingê³¼ metric-scale 3D ì¶”ì •ì„ ë™ì‹œì— ë‹¬ì„±í•˜ì—¬, map ì—†ì´ë„ ì •í™•í•œ pose estimationì´ ê°€ëŠ¥í•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.
- ì¦‰, 3D geometry ì—†ì´ë„ ì´ë¯¸ì§€ ê°„ì˜ ëŒ€ì‘ì ê³¼ ì¹´ë©”ë¼ í¬ì¦ˆë¥¼ ì¶”ì •í•  ìˆ˜ ìˆì–´ Map-free relocalizationì— ì í•©í•©ë‹ˆë‹¤.

#### ğŸ§­ ê¸°ì¡´ relocalizationê³¼ì˜ ì°¨ì´
- Map-based Relocalization:	ê¸°ì¡´ 3D ëª¨ë¸ ë˜ëŠ” í¬ì¸íŠ¸ í´ë¼ìš°ë“œ í•„ìš”
- Map-free Relocalization:	ì‚¬ì „ ì§€ë„ ì—†ì´ ì´ë¯¸ì§€ ê°„ ëŒ€ì‘ë§Œìœ¼ë¡œ í¬ì¦ˆ ì¶”ì •
