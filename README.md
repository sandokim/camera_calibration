## ì»¤ìŠ¤í…€ ì¹´ë©”ë¼ ë³´ì • ë° ìì„¸ ì¶”ì • í”„ë¡œì„¸ìŠ¤ 

### 1. ì¹´ë©”ë¼ ë‚´ë¶€ íŒŒë¼ë¯¸í„° ì¶”ì • (`camera_calibration_intrinsics.py`)
- **ì‹¤í–‰ ë¹ˆë„:** ì¹´ë©”ë¼ë‹¹ í•œ ë²ˆë§Œ ì‹¤í–‰
- **ì…ë ¥:** ì¹´ë©”ë¼ë‹¹ 20ì¥ ì´ìƒì˜ ì²´ì»¤ë³´ë“œ ì´ë¯¸ì§€
- **ëª©ì :** ì¹´ë©”ë¼ì˜ ë‚´ë¶€ íŒŒë¼ë¯¸í„°(ì´ˆì  ê±°ë¦¬, ê´‘í•™ ì¤‘ì‹¬, ì™œê³¡ ê³„ìˆ˜)ë¥¼ êµ¬í•¨
- **ì¶œë ¥:** ê° ì¹´ë©”ë¼ë³„ë¡œ intrinsics.json íŒŒì¼ ìƒì„±

### 2. ì¹´ë©”ë¼ ì™¸ë¶€íŒŒë¼ë¯¸í„° ì¶”ì • (`camera_calibration_extrinsics.py`)
- **ì‹¤í–‰ ë¹ˆë„:** ë°ì´í„°ì…‹ êµ¬ì¶• ì‹œë§ˆë‹¤ ì‹¤í–‰
- **ì…ë ¥:** ë©€í‹° ì¹´ë©”ë¼ ì„¸íŒ…ì—ì„œ ë™ì‹œ ì´¬ì˜ëœ ì²´ì»¤ë³´ë“œ ì´ë¯¸ì§€ ìµœì†Œ 20ì¥ ì´ìƒ
- **ëª©ì :** ê³µí†µëœ í•˜ë‚˜ì˜ ì¢Œí‘œê³„ì—ì„œ ì¹´ë©”ë¼ ì™¸ë¶€ íŒŒë¼ë¯¸í„°(ì¹´ë©”ë¼ í¬ì¦ˆ) ì¶”ì •
- **ì¶œë ¥:**
  - PnP ì•Œê³ ë¦¬ì¦˜ì„ í†µí•´ ì²´ì»¤ë³´ë“œ ì¢Œí‘œê³„(world frame)ì—ì„œ ì¹´ë©”ë¼ ì¢Œí‘œê³„(camera frame)ë¡œì˜ ë³€í™˜ í–‰ë ¬ ê³„ì‚°
  - cam0ë¥¼ referenceë¡œ ì‚¼ê³  ë‚˜ë¨¸ì§€ ì¹´ë©”ë¼ë“¤ì˜ ì™¸ë¶€ íŒŒë¼ë¯¸í„° ê³„ì‚°
  - extrinsics.jsonìœ¼ë¡œ ì¹´ë©”ë¼ í¬ì¦ˆ ì €ì¥ 

checkerboardë¡œ êµ¬í•œ extrinsicsì™€ intrinsicsë¥¼ ë‹¤ìŒê³¼ ê°™ì´ ë³µì‚¬í•˜ê³ ,
scene/face/images/camXì— ë“¤ì–´ìˆëŠ” imageì˜ ì´ë¦„ì„ extrinsics.jsonì— ë§ê²Œ ìˆ˜ì •

```python
+â”€â”€ scene/myface/images


+â”€â”€ scene/myface
â”‚   +â”€â”€ extrinsics.json
â”‚   +â”€â”€ images
â”‚   â”‚   +â”€â”€ cam0
â”‚   â”‚   â”‚   +â”€â”€ cam0_img0.jpg
â”‚   â”‚   â”‚   +â”€â”€ intrinsics.json
â”‚   â”‚   +â”€â”€ cam1
â”‚   â”‚   â”‚   +â”€â”€ cam1_img0.jpg
â”‚   â”‚   â”‚   +â”€â”€ intrinsics.json
â”‚   â”‚   +â”€â”€ cam2
â”‚   â”‚   â”‚   +â”€â”€ cam2_img0.jpg
â”‚   â”‚   â”‚   +â”€â”€ intrinsics.json
â”‚   â”‚   +â”€â”€ cam3
â”‚   â”‚   â”‚   +â”€â”€ cam3_img0.jpg
â”‚   â”‚   â”‚   +â”€â”€ intrinsics.json

+â”€â”€ scene/4_camera_calib_data
â”‚   +â”€â”€ checkerboard
â”‚   â”‚   +â”€â”€ cam0
â”‚   â”‚   â”‚   +â”€â”€ cam0_checkerboard_img0.jpg
â”‚   â”‚   â”‚   +â”€â”€ cam0_checkerboard_img1.jpg
â”‚   â”‚   â”‚   +â”€â”€ cam0_checkerboard_img2.jpg
â”‚   â”‚   â”‚   ...
â”‚   â”‚   â”‚   +â”€â”€ intrinsics.json
â”‚   â”‚   +â”€â”€ cam1
â”‚   â”‚   â”‚   +â”€â”€ cam1_checkerboard_img0.jpg
â”‚   â”‚   â”‚   +â”€â”€ cam1_checkerboard_img1.jpg
â”‚   â”‚   â”‚   +â”€â”€ cam1_checkerboard_img2.jpg
â”‚   â”‚   â”‚   ...
â”‚   â”‚   â”‚   +â”€â”€ intrinsics.json
â”‚   â”‚   +â”€â”€ cam2
â”‚   â”‚   â”‚   +â”€â”€ cam2_checkerboard_img0.jpg
â”‚   â”‚   â”‚   +â”€â”€ cam2_checkerboard_img1.jpg
â”‚   â”‚   â”‚   +â”€â”€ cam2_checkerboard_img2.jpg
â”‚   â”‚   â”‚   ...
â”‚   â”‚   â”‚   +â”€â”€ intrinsics.json
â”‚   â”‚   +â”€â”€ cam3
â”‚   â”‚   â”‚   +â”€â”€ cam3_checkerboard_img0.jpg
â”‚   â”‚   â”‚   +â”€â”€ cam3_checkerboard_img1.jpg
â”‚   â”‚   â”‚   +â”€â”€ cam3_checkerboard_img2.jpg
â”‚   â”‚   â”‚   ...
â”‚   â”‚   â”‚   +â”€â”€ intrinsics.json
â”‚   â”‚   +â”€â”€ multicapture
â”‚   â”‚   â”‚   +â”€â”€ cam0
â”‚   â”‚   â”‚   â”‚   +â”€â”€ cam0_checkerborard_img_x.jpg
â”‚   â”‚   â”‚   +â”€â”€ cam1
â”‚   â”‚   â”‚   â”‚   +â”€â”€ cam1_checkerborard_img_x.jpg
â”‚   â”‚   â”‚   +â”€â”€ cam2
â”‚   â”‚   â”‚   â”‚   +â”€â”€ cam2_checkerborard_img_x.jpg
â”‚   â”‚   â”‚   +â”€â”€ cam3
â”‚   â”‚   â”‚   â”‚   +â”€â”€ cam3_checkerborard_img_x.jpg
â”‚   â”‚   +â”€â”€ extrinsics.json
â”‚   â”‚   +â”€â”€ other_scene_images
```


### 3. COLMAP í˜•íƒœì˜ cameras.txt, images.txtë¡œ ì €ì¥
- **ì…ë ¥:** intrinsics.json, extrinsics.json
- **ëª©ì :** COLMAP í˜•íƒœì˜ ì¹´ë©”ë¼ íŒŒë¼ë¯¸í„° ì €ì¥
- **ì¶œë ¥:** cameras.txt, images.txt, points3D.txt(empty)


### 4. sparse/0/ í´ë” ìƒì„± í›„ 3.ì—ì„œ ì¶œë ¥í•œ cameras.txt, images.txt, points3D.txt(empty)ë¥¼ ë³µì‚¬
https://colmap.github.io/faq.html#reconstruct-sparse-dense-model-from-known-camera-poses
If the camera poses are known and you want to reconstruct a sparse or dense model of the scene, you must first manually construct a sparse model by creating a cameras.txt, points3D.txt, and images.txt under a new folder:

python convert_to_COLMAP_fmt.pyë¥¼ ì‹¤í–‰í•˜ë©´ ë‹¤ìŒê³¼ ê°™ì€ í´ë”ê°€ ìƒì„±ë˜ê³ , triangulationì´ ìˆ˜í–‰ë˜ì–´, triangulated/sparse/0 í´ë”ê°€ ìƒì„±ë¨
COLMAPì˜ model_convertë¥¼ í†µí•´ triangulated/sparse/0 í´ë”ì— ìƒì„±ëœ bin íŒŒì¼ì„ txt íŒŒì¼ í˜•ì‹ìœ¼ë¡œë„ ë³€í™˜í•˜ì—¬ ì €ì¥

```python
+â”€â”€ manually/created/sparse/model
â”‚   +â”€â”€ cameras.txt
â”‚   +â”€â”€ images.txt
â”‚   +â”€â”€ points3D.txt
+â”€â”€ triangulated/sparse/0
â”‚   +â”€â”€ cameras.txt
â”‚   +â”€â”€ images.txt
â”‚   +â”€â”€ points3D.txt
â”‚   +â”€â”€ cameras.bin
â”‚   +â”€â”€ images.bin
â”‚   +â”€â”€ points3D.bin
```

The points3D.txt file should be empty while every other line in the images.txt should also be empty, since the sparse features are computed, as described below. You can refer to this article for more information about the structure of a sparse model.

#### COLMAPì—ì„œ Import Modelë¡œ sparse/0/ í´ë” ì„ íƒí•˜ì˜€ìœ¼ë‚˜ COLMAP Processing > Database managementì—ì„œ Camerasì™€ Imagesê°€ ëª¨ë‘ ë¹„ì–´ìˆìŒ

COLMAPì€ .txt íŒŒì¼ ê¸°ë°˜ì˜ ëª¨ë¸ì„ GUIì—ì„œ ì§ì ‘ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ëŒ€ì‹  database.dbë¥¼ ì§ì ‘ êµ¬ì„±í•˜ê±°ë‚˜ ë³€í™˜í•˜ì—¬ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ìœ ì¼í•œ ë°©ë²•ì…ë‹ˆë‹¤. GUI/CLI ëª¨ë‘ ë™ì¼í•˜ê²Œ database.db â†’ ëª¨ë“  ì´ë¯¸ì§€, ì¹´ë©”ë¼, feature ì •ë³´ ì‚¬ìš©

The image reader can only take the parameters for a single camera. If you want to specify the parameters for multiple cameras, you would have to modify the SQLite database directly. This should be easy by modifying the scripts/python/database.py script.

#### Question: How to format cameras.txt for Reconstruct sparse/dense model from known camera poses #428 
different cameras with different intrinsics, multiple camerasì˜ parametersë¥¼ ì§€ì •í•˜ë ¤ë©´ SQLite databaseë¥¼ ì§ì ‘ ìˆ˜ì •í•´ì•¼í•˜ê³ , ì´ëŠ” `colmap/scripts/python/database.py` ìŠ¤í¬ë¦½íŠ¸ë¡œ ê°€ëŠ¥í•˜ë‹¤
https://github.com/colmap/colmap/issues/428

#### gaussian_splattingì„ ìœ„í•´ì„  convert_to_COLMAP_fmt.pyì—ì„œ OpenCV ì¹´ë©”ë¼ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì˜€ê¸°ì—, intrinsicsë¥¼ ì‚¬ìš©í•˜ì—¬, undistortioní•œ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•˜ì—¬ì•¼ í•¨
- undistortionì´ ì•„ì§ ì•ˆëœ ì´ë¯¸ì§€ë“¤ì„ -> multicam/build/Desktop_Qt_6_9_0_MSVC2022_64bit-Release/scene/myface_undistort/input ì— ë„£ê¸°
- multicam/build/Desktop_Qt_6_9_0_MSVC2022_64bit-Release/scene/myface_undistort/distorted í´ë” ì•ˆì— database.dbì™€ triangulated/sparse/0 í´ë”ë¥¼ ë³µì‚¬

```python
<location>
|---input
|   |---<image 0>
|   |---<image 1>
|   |---...
|---distorted
    |---database.db
    |---sparse
        |---0
            |---...
```

# ì•„ì§ undistortionì´ ì•ˆëœ imagesë¥¼ input í´ë”ì— ë„£ê³ , convert.pyë¥¼ ì‹¤í–‰í•˜ë©´ undistortedëœ ì´ë¯¸ì§€ë“¤ì€ images í´ë”ì— ìƒì„±ë¨
# triangulated/sparse/0ì—ì„œ ì–»ì—ˆë˜ cameras.txt, images.txt, points3D.txt -> distorted/sparse/0ì— ë³µì‚¬í–ˆìŒ
# ë¯¸ë¦¬ COLMAPì˜ feature extraction, feature matchingì„ ì‹¤í–‰í•˜ì—¬, database.dbì— ì €ì¥í–ˆì—ˆê¸° ë•Œë¬¸ì—, convert.pyì—ì„œëŠ” feature extraction, feature matchingì„ ì‹¤í–‰í•˜ì§€ ì•ŠìŒ -> convert.pyì—ì„œ skip matchingì„ í•˜ë©´ feature extraction, feature matching, mapper((SfM & triangulation) + bundle adjustment)ì„ ì‹¤í–‰í•˜ì§€ ì•ŠìŒ

### ë³¸ì¸ì€ convert_to_COLMAP_fmt.pyì—ì„œ feature extraction, feature matchingì„ ìˆ˜í–‰í•˜ê³ , ë¯¸ë¦¬ PnP ì•Œê³ ë¦¬ì¦˜ì„ í†µí•´ ê³„ì‚°í•œ ì¹´ë©”ë¼ í¬ì¦ˆë¥¼ ì£¼ì—ˆê³ , ì´ ì¹´ë©”ë¼ í¬ì¦ˆë¥¼ ì‚¬ìš©í•˜ì—¬ point triangulatorë¥¼ ìˆ˜í–‰í•˜ì˜€ì§€ë§Œ, bundle adjustmentëŠ” ì‹¤í–‰í•˜ì§€ ì•Šì•˜ìŒ -> bundle adjustmentë„ ì¶”ê°€í•˜ì
### **Bundle Adjustment(BA)**ë¥¼ ìˆ˜í–‰í•˜ì§€ ì•Šìœ¼ë©´ í¬ì¦ˆ ë° 3D êµ¬ì¡° ê°„ì˜ ì •í•© ìµœì í™”ê°€ ì´ë£¨ì–´ì§€ì§€ ì•ŠìŒ
### ë‹¨, bundle adjustmentëŠ” feature matchingì—ì„œ ì°¾ì•„ì§„ ëŒ€ì‘ì  ê´€ê³„ê°€ ë¶€ì •í™•í•˜ë©´, triangulationìœ¼ë¡œ ì°¾ì•„ì§„ 3D ì ë“¤ì˜ ìœ„ì¹˜ë„ ë¶€ì •í™•í•´ì§ˆ ìˆ˜ ìˆê³ , bundle adjustment ê²°ê³¼ë„ ë¶€ì •í™•í•´ì§ˆ ìˆ˜ ìˆìŒ
- BAëŠ” ê¸°ì¡´ì˜ 3D êµ¬ì¡°ì™€ ì¹´ë©”ë¼ í¬ì¦ˆë¥¼ ì •ë°€í•˜ê²Œ ì •í•©í•˜ëŠ” ìµœì í™” ê³¼ì •ì…ë‹ˆë‹¤.
- í•˜ì§€ë§Œ, **ì´ˆê¸° ì…ë ¥ê°’(3D ì , ëŒ€ì‘ì , í¬ì¦ˆ)**ì´ ë¶€ì •í™•í•˜ê±°ë‚˜ ë¶€ì¡±í•˜ë‹¤ë©´, BAëŠ”:
- ì˜¤ì°¨ë¥¼ ì¤„ì´ëŠ” ëŒ€ì‹ , ì˜ëª»ëœ ë°©í–¥ìœ¼ë¡œ ìˆ˜ë ´í•˜ê±°ë‚˜
- **ê³¼ì í•©(overfitting)**ì˜ í˜•íƒœë¡œ ìˆ˜ë ´í•  ìˆ˜ ìˆìŒ
- 3D ì ì˜ ë°€ë„ê°€ ì¶©ë¶„í•˜ì§€ ì•Šì„ ê²½ìš°
- reconstructëœ 3D ì ë“¤ì´ sparseí•˜ê³ , ì¥ë©´ êµ¬ì¡°ë¥¼ ì¶©ë¶„íˆ í¬ê´„í•˜ì§€ ëª»í•˜ë©´:
- ì¹´ë©”ë¼ í¬ì¦ˆ ê°„ ì œì•½ ì¡°ê±´ì´ ì•½í•´ì§
- ëŒ€ì‘ì  ê¸°ë°˜ ì—ëŸ¬ ìµœì†Œí™”ê°€ ì „ì²´ ì¥ë©´ ì •í•©ì„±ìœ¼ë¡œ ì—°ê²°ë˜ì§€ ì•ŠìŒ
- ì´ëŸ° ê²½ìš° BAë¥¼ ìˆ˜í–‰í•´ë„ ìµœì í™”ì— ì¶©ë¶„í•œ ì •ë³´ê°€ ë¶€ì¡±í•˜ì—¬, ê²°ê³¼ê°€ ë¬´ì˜ë¯¸í•˜ê±°ë‚˜ ì˜¤íˆë ¤ ë‚˜ë¹ ì§ˆ ìˆ˜ ìˆìŒ

### convert.pyì—ì„œëŠ” feature extraction, feature matching, mapper ê°€ ìˆ˜í–‰ë˜ì—ˆê³ , mapperëŠ” ì¹´ë©”ë¼ í¬ì¦ˆ ê³„ì‚° (SfM)ê³¼ triangulationì„ ìˆ˜í–‰í•œ í›„ì— (local+global) bundle adjustmentë¥¼ ìˆ˜í–‰í•¨

```
python convert.py -s multicam/build/Desktop_Qt_6_9_0_MSVC2022_64bit-Release/scene/myface_undistort --skip_matching
```

ê° ì¹´ë©”ë¼ë§ˆë‹¤ intrinsicsê°€ ë‹¬ëì–´ì„œ, undistortionëœ ì´ë¯¸ì§€ë“¤ì˜ ì‚¬ì´ì¦ˆê°€ ë‹¤ë¥´ê²Œ ìƒì„±ë¨

# ì„ì‹œë¡œ í•´ê²°í•œ ë¶€ë¶„.. í™•ì‹¤íˆ í•´ì•¼í•¨
image_undistorterëŠ” ì´ë¯¸ì§€ë¥¼ ideal pinhole camera ëª¨ë¸ë¡œ ë³€í™˜í•˜ëŠ” ê³¼ì •ì—ì„œ, projection ì¤‘ì‹¬(cx, cy) ê¸°ì¤€ìœ¼ë¡œ ìœ íš¨í•œ ì‹œì•¼ ì˜ì—­ë§Œì„ ìœ ì§€í•¨
ë”°ë¼ì„œ intrinsicsì˜ cx, cyê°€ ì´ë¯¸ì§€ ì¤‘ì‹¬ì—ì„œ í¬ê²Œ ë²—ì–´ë‚œ ê²½ìš°, warped ì˜ì—­ì´ ì´ë¯¸ì§€ ë°–ìœ¼ë¡œ ë°€ë ¤ cropì´ ì‹¬í•˜ê²Œ ë°œìƒí•¨
## camera_calibration_intrinsics.pyì—ì„œ ì²´ì»¤ë³´ë“œ íŒ¨í„´ìœ¼ë¡œ ì¶”ì •í•œ intrinsicsì¸ mtxì—ì„œ ì„ì˜ë¡œ mtx[0,2] = W/2, mtx[1,2] = H/2ë¡œ ëŒ€ì²´í•˜ì—¬ì„œ cropì´ ì‹¬í•˜ê²Œ ë˜ëŠ” ë¶€ë¶„ì´ í•´ê²°ë˜ì—ˆìŒ

## image_undistorter ëª…ë ¹
- ì™œê³¡ ì œê±°ëœ ì´ë¯¸ì§€ì™€ í•¨ê»˜, ì´ ì´ë¯¸ì§€ì— ë§ëŠ” ideal PINHOLE (ë˜ëŠ” SIMPLE_PINHOLE) ì¹´ë©”ë¼ ëª¨ë¸ì„ ìƒì„±í•¨
- 'image undistorter' ëª…ë ¹ì„ ìˆ˜í–‰í•œë‹¤ê³  í•´ì„œ database.db ë‚´ OpenCV ëª¨ë¸ì´ PINHOLEë¡œ ìë™ ë³€í™˜ë˜ì§€ëŠ” ì•ŠìŠµë‹ˆë‹¤.
- ëŒ€ì‹ , undistorted ê²°ê³¼ì— ëŒ€ì‘í•˜ëŠ” PINHOLE ëª¨ë¸ì´ ë³„ë„ íŒŒì¼(cameras.txt ë“±)ì— ìƒì„±ë  ë¿ì…ë‹ˆë‹¤.

### poses_bounds.npy ìƒì„±
git clone https://github.com/Fyusion/LLFF
python LLFF/imgs2poses.py multicam/build/Desktop_Qt_6_9_0_MSVC2022_64bit-Release/scene/myface_undistort

### GS í•™ìŠµ ì„±ê³µ!
```python
<KIST_llff>
|---images
|   |---<image 0>
|   |---<image 1>
|   |---...
|---sparse
|    |---0
|        |---cameras.bin
|        |---images.bin
|        |---points3D.bin
|---poses_bounds.npy   
```

# í• ì¼
### feature extractionì„ denseí•˜ê²Œ ìˆ˜í–‰í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•˜ê³ , feature matchingì„ ìˆ˜í–‰í•˜ê³ , PnP ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ êµ¬í•œ ì¹´ë©”ë¼ í¬ì¦ˆì™€ í•¨ê»˜, ì•ì„œ êµ¬í•œ feature matchingìœ¼ë¡œ ì°¾ì•„ì§„ correspondencesê°€ 2ê°œ ì´ìƒì¼ ê²½ìš°ì—ë„ triangulationí•˜ì—¬ 3D í¬ì¸íŠ¸ë¥¼ reconstructí•˜ëŠ” ì•Œê³ ë¦¬ì¦˜ì„ êµ¬í˜„í•´ì•¼í•˜ê³ , ì¶”ê°€ì ìœ¼ë¡œ ì¹´ë©”ë¼ í¬ì¦ˆ ë° 3D êµ¬ì¡°ê°„ì˜ ì •í•© ìµœì í™”ë¥¼ ìœ„í•œ Bundle Adjustment(BA)ë¥¼ ìˆ˜í–‰í•´ì•¼ë§Œ í•¨

triangulate_from_known_poses_and_matches.py
https://github.com/opencv/opencv_contrib/blob/master/modules/sfm/src/triangulation.cpp
cv2.sfm ëª¨ë“ˆì€ OpenCVì˜ contrib ëª¨ë“ˆ ì¤‘ í•˜ë‚˜ì´ë©°, ê¸°ë³¸ OpenCV ì„¤ì¹˜ì—ëŠ” í¬í•¨ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. cv2.sfmì„ ì‚¬ìš©í•˜ë ¤ë©´ OpenCVë¥¼ ì†ŒìŠ¤ì—ì„œ ì§ì ‘ ë¹Œë“œí•´ì•¼í•¨

```python
import os, sys

# DLL ê²½ë¡œ
os.add_dll_directory("C:/Users/maila/opencv/build/bin/Release")
# .pyd ê²½ë¡œ
sys.path.append("C:/Users/maila/opencv/build/lib/python3/Release")

# OpenCV import ì‹œë„
import cv2
print("sfm ëª¨ë“ˆ:", cv2.sfm)
```

### cv2.sfmì„ ì‚¬ìš©í•˜ê¸° ìœ„í•œ python 3.12 ê°€ìƒí™˜ê²½ ìƒˆë¡œ êµ¬ì¶• (C:/Users/maila/opencv/build/lib/python3/Release/cv2.cp312-win_amd64.pyd)
conda create -n opencv_sfm_py312 python=3.12
conda activate opencv_sfm_py312
pip install numpy
pip install matplotlib
pip install open3d


# ğŸ” ìš©ì–´ ì •ë¦¬: "Dense Reconstruction"
1. ì •í™•í•œ ì •ì˜ (ì „í†µì  ì˜ë¯¸)
Dense reconstructionì€ ì¼ë°˜ì ìœ¼ë¡œ MVS (Multi-View Stereo) ë¥¼ í†µí•´ ì¥ë©´ì˜ í‘œë©´ì„ ì¡°ë°€í•œ 3D í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ë˜ëŠ” ë©”ì‰¬ë¡œ ë³µì›í•˜ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤.

ì´ë•ŒëŠ” triangulated sparse pointsê°€ ì•„ë‹Œ,

í”½ì…€ ë‹¨ìœ„ë¡œ ëŒ€ì‘ì ì„ ì°¾ê³  ê¹Šì´ ì •ë³´ë¥¼ ì¶”ì •í•˜ì—¬ ìˆ˜ì‹­ë§Œ~ìˆ˜ë°±ë§Œ ê°œì˜ 3D ì ì„ ìƒì„±í•©ë‹ˆë‹¤.

â†’ COLMAPì—ì„œë„ MVSë¥¼ ì‚¬ìš©í•œ patch_match_stereo, stereo_fusion ì´í›„ê°€ ì§„ì§œ dense reconstructionì…ë‹ˆë‹¤.

2. í”í•œ í˜¼ë™: Dense feature ì‚¬ìš© = dense reconstruction?
ì–´ë–¤ ì—°êµ¬ë‚˜ êµ¬í˜„ì—ì„œëŠ” dense feature matcher (e.g., LoFTR, DISK, D2-Net)ë§Œ ì‚¬ìš©í•´ë„ ì´ë¥¼ "dense reconstruction"ì´ë¼ ë¶€ë¥´ëŠ” ê²½ìš°ê°€ ìˆìŠµë‹ˆë‹¤.

í•˜ì§€ë§Œ ì—„ë°€íˆ ë³´ë©´ ì´ê±´:

dense correspondences ê¸°ë°˜ì˜ SfM ë˜ëŠ”

dense SfM
ì´ë¼ê³  ë¶€ë¥´ëŠ” ê²Œ ë” ì •í™•í•©ë‹ˆë‹¤.